# Real-Time-Fraud-Detection-System

Use Case Overview:

Building a system to detect fraudulent financial transactions in real time. The system should:
	â€¢	Ingest transactions as they happen
	â€¢	Enrich with reference data (e.g., blacklist, geo data)
	â€¢	Identify suspicious patterns (e.g., multiple withdrawals in seconds, location mismatch)
	â€¢	Trigger alerts and store data for historical analysis

ðŸ§± Architecture Overview:
[Database/Apps/ATM] â†’ NiFi â†’ Kafka â†’ Flink + SQL Stream Builder â†’ Kafka/HBase/Phoenix â†’ Alerts/Hive
                                       â†˜
                                 Real-time Rules

âš™ï¸ Components and Responsibilities

1. Kafka (Stream Transport)
	â€¢	Source Topics: transactions, user_profile, geo_blacklist
	â€¢	Messages include:
	â€¢	transaction_id, account_id, timestamp, amount, location, device_id, channel

â¸»

2. Schema Registry
	â€¢	Define schemas for each topic using Avro or JSON
	â€¢	Ensures consistent serialization/deserialization between NiFi â†’ Kafka â†’ Flink

â¸»

3. NiFi (Data Ingestion & Enrichment)
	â€¢	Ingest from:
	â€¢	REST APIs (mobile, web, ATM)
	â€¢	RDBMS (CDC via Debezium, JDBC polling)
	â€¢	Transform and enrich:
	â€¢	Add geolocation, device reputation, account type
	â€¢	Route to appropriate Kafka topic

ðŸ’¡ Example processors:
	â€¢	ConvertRecord (JSON to Avro)
	â€¢	UpdateRecord (enrich with NiFi LookupService)
	â€¢	PublishKafkaRecord_2_6

â¸»

4. Flink + SQL Stream Builder (Real-Time Fraud Logic)

Fraud detection examples:
	â€¢	Velocity check: 3+ transactions within 10 seconds
	â€¢	Geo anomaly: user logged in from Jakarta, then next ATM withdrawal from New York in 1 minute
	â€¢	High value: Amount > defined threshold for this account type

Use SQL Stream Builder (SSB) for rule-based detection:
SELECT
  account_id,
  COUNT(*) AS txn_count,
  TUMBLE_START(proctime, INTERVAL '10' SECOND) as window_start
FROM
  transactions
GROUP BY
  TUMBLE(proctime, INTERVAL '10' SECOND), account_id
HAVING
  txn_count > 3

Or use pattern matching (CEP) for event sequences:
SELECT *
FROM PATTERN (
  A -> B -> C
  WHERE A.amount > 1000 AND B.amount > 1000 AND C.amount > 1000
  WITHIN INTERVAL '30' SECONDS
)

5. Phoenix + HBase (Real-Time Data Store)
	â€¢	Store:
	â€¢	User profile cache (for joins)
	â€¢	Recent flagged events (for alert de-duplication)
	â€¢	Fast lookup/update of flags, counters, risk scores

ðŸ’¡ Example:
	â€¢	Table: fraud_flags
	â€¢	Columns: account_id, last_flagged_time, fraud_score

6. Hive (Analytics & BI)
	â€¢	Archive all events
	â€¢	Build dashboards in Hue / Power BI / Looker
	â€¢	Train ML models for advanced fraud detection (offline)

7. Optional: Alerting System
	â€¢	Flink output â†’ Kafka topic fraud_alerts
	â€¢	NiFi or microservice subscribes and triggers:
	â€¢	Email/SMS
	â€¢	Case creation in CRM
	â€¢	Risk engine updates

ðŸ“‚ Folder Structure (Sample)
fraud-detection/
â”œâ”€â”€ nifi/
â”‚   â”œâ”€â”€ templates/
â”‚   â””â”€â”€ lookups/
â”œâ”€â”€ flink/
â”‚   â”œâ”€â”€ sql/
â”‚   â””â”€â”€ cep/
â”œâ”€â”€ schema-registry/
â”‚   â””â”€â”€ avro/
â”œâ”€â”€ kafka/
â”‚   â””â”€â”€ topics.txt
â”œâ”€â”€ hive/
â”‚   â””â”€â”€ table-definitions/
â”œâ”€â”€ phoenix/
â”‚   â””â”€â”€ table-create.sql
